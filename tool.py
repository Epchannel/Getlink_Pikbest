import requests
import re
import os
import json
import logging
from selenium import webdriver
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from dotenv import load_dotenv
import time

# T·∫£i bi·∫øn m√¥i tr∆∞·ªùng t·ª´ file .env
load_dotenv()

# Thi·∫øt l·∫≠p logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Kh·ªüi t·∫°o cookies t·ª´ bi·∫øn m√¥i tr∆∞·ªùng
def load_cookies_from_env():
    cookies_str = os.getenv('PIKBEST_COOKIES')
    if not cookies_str:
        logger.warning("Kh√¥ng t√¨m th·∫•y PIKBEST_COOKIES trong file .env")
        return {}
    
    try:
        return json.loads(cookies_str)
    except json.JSONDecodeError:
        logger.error("Kh√¥ng th·ªÉ parse PIKBEST_COOKIES t·ª´ .env, ƒë·ªãnh d·∫°ng JSON kh√¥ng h·ª£p l·ªá")
        return {}

PIKBEST_COOKIES = load_cookies_from_env()

# T·∫°o session v√† headers gi·ªëng tr√¨nh duy·ªát
session = requests.Session()
session.cookies.update(PIKBEST_COOKIES)

headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
    "Accept-Language": "en-US,en;q=0.9",
    "Referer": "https://www.pikbest.com/",
}

def get_real_download_link(file_id):
    download_api_url = f"https://pikbest.com/?m=download&id={file_id}&flag=1"
    logger.info(f"ƒêang truy c·∫≠p URL download: {download_api_url}")

    options = Options()
    options.add_argument("--headless")
    options.add_argument("--disable-gpu")
    options.add_argument("--no-sandbox")
    options.add_argument(f"user-agent={headers['User-Agent']}")
    # Th√™m c√°c options ƒë·ªÉ tr√°nh ph√°t hi·ªán automation
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)
    
    driver = webdriver.Chrome(options=options)

    try:
        # ƒê·∫∑t k√≠ch th∆∞·ªõc c·ª≠a s·ªï tr√¨nh duy·ªát
        driver.set_window_size(1920, 1080)
        
        # Th√™m cookies v√†o tr√¨nh duy·ªát
        driver.get("https://pikbest.com")
        logger.info("ƒêang th√™m cookies v√†o tr√¨nh duy·ªát...")
        for name, value in PIKBEST_COOKIES.items():
            driver.add_cookie({"name": name, "value": value})
        
        # Truy c·∫≠p trang ch√≠nh ƒë·ªÉ x√°c nh·∫≠n ƒëƒÉng nh·∫≠p
        driver.get("https://pikbest.com/my/")
        time.sleep(3)  # ƒê·ª£i ƒë·ªÉ x√°c nh·∫≠n ƒëƒÉng nh·∫≠p
        
        # Ki·ªÉm tra xem ƒë√£ ƒëƒÉng nh·∫≠p th√†nh c√¥ng ch∆∞a
        if "login" in driver.current_url.lower():
            logger.warning("Ch∆∞a ƒëƒÉng nh·∫≠p th√†nh c√¥ng, ƒëang th·ª≠ ƒëƒÉng nh·∫≠p l·∫°i...")
            # C√≥ th·ªÉ th√™m logic ƒëƒÉng nh·∫≠p ·ªü ƒë√¢y n·∫øu c·∫ßn
        
        # Truy c·∫≠p trang download
        logger.info(f"ƒêang truy c·∫≠p trang download: {download_api_url}")
        driver.get(download_api_url)
        
        # ƒê·ª£i l√¢u h∆°n ƒë·ªÉ trang load ho√†n to√†n v√† hi·ªán n√∫t "Click here"
        time.sleep(7)  # ƒê·ª£i √≠t nh·∫•t 5 gi√¢y + th√™m 2 gi√¢y ƒë·ªÉ ch·∫Øc ch·∫Øn
        
        # L∆∞u screenshot ƒë·ªÉ debug
        screenshot_path = "debug_screenshot.png"
        driver.save_screenshot(screenshot_path)
        logger.info(f"ƒê√£ l∆∞u screenshot t·∫°i: {screenshot_path}")
        
        # L∆∞u source HTML ƒë·ªÉ debug
        with open("page_source.html", "w", encoding="utf-8") as f:
            f.write(driver.page_source)
        logger.info("ƒê√£ l∆∞u source HTML t·∫°i: page_source.html")
        
        # Th√™m script ƒë·ªÉ b·∫Øt Ajax requests
        driver.execute_script("""
            window.ajaxRequests = [];
            window.downloadLinks = [];
            
            // B·∫Øt XHR requests
            var originalXHROpen = XMLHttpRequest.prototype.open;
            var originalXHRSend = XMLHttpRequest.prototype.send;
            
            XMLHttpRequest.prototype.open = function(method, url) {
                this._url = url;
                this._method = method;
                originalXHROpen.apply(this, arguments);
            };
            
            XMLHttpRequest.prototype.send = function() {
                var xhr = this;
                this.addEventListener('load', function() {
                    try {
                        var url = xhr._url || xhr.responseURL;
                        if (url) {
                            window.ajaxRequests.push({
                                url: url,
                                method: xhr._method,
                                status: xhr.status,
                                response: xhr.responseText
                            });
                            
                            // Ki·ªÉm tra n·∫øu l√† Ajax download request
                            if (url.includes('AjaxDownload') && url.includes('a=open')) {
                                console.log('Detected AjaxDownload request:', url);
                                console.log('Response:', xhr.responseText);
                                
                                // Th·ª≠ parse JSON response
                                try {
                                    var jsonResponse = JSON.parse(xhr.responseText);
                                    if (jsonResponse && jsonResponse.url) {
                                        window.downloadLinks.push(jsonResponse.url);
                                    }
                                } catch (e) {
                                    console.error('Error parsing JSON:', e);
                                }
                            }
                            
                            // Ki·ªÉm tra c√°c URL t·∫£i
                            if (url && (url.includes('.zip') || url.includes('.psd') || 
                                       url.includes('.ai') || url.includes('.jpg') || 
                                       url.includes('.png') || url.includes('.pdf') || 
                                       url.includes('.eps') || url.includes('.rar'))) {
                                if (!url.includes('logo') && !url.includes('icon') && 
                                    !url.includes('favicon') && !url.includes('avatar')) {
                                    window.downloadLinks.push(url);
                                }
                            }
                        }
                    } catch (e) {
                        console.error('Error in XHR tracking:', e);
                    }
                });
                originalXHRSend.apply(this, arguments);
            };
        """)
        
        # Ph∆∞∆°ng ph√°p 1: T√¨m v√† click n√∫t "Click here" tr·ª±c ti·∫øp
        logger.info("ƒêang t√¨m n√∫t 'Click here'...")
        try:
            # T√¨m theo nhi·ªÅu c√°ch kh√°c nhau
            click_here_selectors = [
                "/html/body/div[3]/div/div[1]/div/div[2]/div/p[1]/a",
                "//a[contains(text(), 'Click here')]",
                "//a[@onclick='if (!window.__cfRLUnblockHandlers) return false; downloadImage()']",
                "//a[contains(@onclick, 'downloadImage')]",
                "//a[contains(@class, 'download')]",
                "//button[contains(@class, 'download')]",
                "//a[contains(@href, 'javascript')]"
            ]
            
            click_here_button = None
            for selector in click_here_selectors:
                elements = driver.find_elements(By.XPATH, selector)
                if elements and elements[0].is_displayed():
                    click_here_button = elements[0]
                    logger.info(f"T√¨m th·∫•y n√∫t t·∫£i v·ªõi selector: {selector}")
                    break
            
            if click_here_button:
                logger.info(f"ƒêang click v√†o n√∫t: {click_here_button.text}")
                # S·ª≠ d·ª•ng JavaScript ƒë·ªÉ click ƒë·ªÉ tr√°nh l·ªói stale element
                driver.execute_script("arguments[0].click();", click_here_button)
                time.sleep(5)  # ƒê·ª£i l√¢u h∆°n sau khi click
                
                # Ki·ªÉm tra Ajax requests
                ajax_requests = driver.execute_script("return window.ajaxRequests;")
                if ajax_requests:
                    logger.info(f"T√¨m th·∫•y {len(ajax_requests)} Ajax requests")
                    
                    # T√¨m Ajax request li√™n quan ƒë·∫øn download
                    for req in ajax_requests:
                        if isinstance(req, dict) and 'url' in req:
                            url = req['url']
                            if 'AjaxDownload' in url and 'a=open' in url:
                                logger.info(f"T√¨m th·∫•y Ajax download request: {url}")
                                
                                # Ki·ªÉm tra response
                                if 'response' in req:
                                    try:
                                        response_data = json.loads(req['response'])
                                        logger.info(f"Ajax response: {response_data}")
                                        
                                        # N·∫øu response c√≥ URL, s·ª≠ d·ª•ng n√≥
                                        if 'url' in response_data and response_data['url']:
                                            logger.info(f"T√¨m th·∫•y URL t·ª´ Ajax response: {response_data['url']}")
                                            return response_data['url']
                                        
                                        # N·∫øu response c√≥ data, th·ª≠ t√¨m URL trong ƒë√≥
                                        if 'data' in response_data and response_data['data']:
                                            if isinstance(response_data['data'], str) and 'http' in response_data['data']:
                                                logger.info(f"T√¨m th·∫•y URL t·ª´ Ajax response data: {response_data['data']}")
                                                return response_data['data']
                                    except Exception as e:
                                        logger.error(f"L·ªói khi parse Ajax response: {e}")
                                
                                # N·∫øu kh√¥ng t√¨m th·∫•y URL trong response, th·ª≠ g·ªçi tr·ª±c ti·∫øp Ajax request
                                try:
                                    logger.info(f"ƒêang g·ªçi tr·ª±c ti·∫øp Ajax request: {url}")
                                    ajax_response = session.get(url, headers=headers)
                                    if ajax_response.status_code == 200:
                                        try:
                                            ajax_data = ajax_response.json()
                                            logger.info(f"Ajax direct response: {ajax_data}")
                                            
                                            if 'url' in ajax_data and ajax_data['url']:
                                                logger.info(f"T√¨m th·∫•y URL t·ª´ direct Ajax: {ajax_data['url']}")
                                                return ajax_data['url']
                                                
                                            if 'data' in ajax_data and ajax_data['data']:
                                                if isinstance(ajax_data['data'], str) and 'http' in ajax_data['data']:
                                                    logger.info(f"T√¨m th·∫•y URL t·ª´ direct Ajax data: {ajax_data['data']}")
                                                    return ajax_data['data']
                                        except Exception as e:
                                            logger.error(f"L·ªói khi parse direct Ajax response: {e}")
                                except Exception as e:
                                    logger.error(f"L·ªói khi g·ªçi tr·ª±c ti·∫øp Ajax request: {e}")
                
                # Ki·ªÉm tra download links
                download_links = driver.execute_script("return window.downloadLinks;")
                if download_links and len(download_links) > 0:
                    for link in download_links:
                        if not any(keyword in link.lower() for keyword in ['logo', 'icon', 'favicon', 'avatar']):
                            logger.info(f"T√¨m th·∫•y link t·∫£i t·ª´ download links: {link}")
                            return link
                
                # Ph∆∞∆°ng ph√°p m·ªõi: Tr√≠ch xu·∫•t hash t·ª´ HTML v√† t·∫°o Ajax URL
                try:
                    logger.info("ƒêang t√¨m hash trong HTML...")
                    page_source = driver.page_source
                    
                    # T√¨m hash trong HTML
                    hash_match = re.search(r'__hash__=([a-f0-9_]+)', page_source)
                    if hash_match:
                        hash_value = hash_match.group(1)
                        logger.info(f"T√¨m th·∫•y hash: {hash_value}")
                        
                        # T·∫°o Ajax URL
                        ajax_url = f"https://pikbest.com/?m=AjaxDownload&a=open&id={file_id}&__hash__={hash_value}&flag=1"
                        logger.info(f"ƒêang g·ªçi Ajax URL: {ajax_url}")
                        
                        # G·ªçi Ajax URL
                        ajax_response = session.get(ajax_url, headers=headers)
                        if ajax_response.status_code == 200:
                            try:
                                ajax_data = ajax_response.json()
                                logger.info(f"Ajax response: {ajax_data}")
                                
                                if 'url' in ajax_data and ajax_data['url']:
                                    logger.info(f"T√¨m th·∫•y URL t·ª´ Ajax: {ajax_data['url']}")
                                    return ajax_data['url']
                                    
                                if 'data' in ajax_data and ajax_data['data']:
                                    if isinstance(ajax_data['data'], str) and 'http' in ajax_data['data']:
                                        logger.info(f"T√¨m th·∫•y URL t·ª´ Ajax data: {ajax_data['data']}")
                                        return ajax_data['data']
                            except Exception as e:
                                logger.error(f"L·ªói khi parse Ajax response: {e}")
                except Exception as e:
                    logger.error(f"L·ªói khi t√¨m hash v√† g·ªçi Ajax: {e}")
        except Exception as e:
            logger.error(f"L·ªói khi t√¨m v√† click n√∫t 'Click here': {e}")
        
        # Ph∆∞∆°ng ph√°p 2: T√¨m trong HTML v√† JavaScript
        logger.info("ƒêang t√¨m link trong HTML v√† JavaScript...")
        try:
            # T√¨m t·∫•t c·∫£ c√°c script tags
            scripts = driver.find_elements(By.TAG_NAME, "script")
            for script in scripts:
                try:
                    script_content = script.get_attribute("innerHTML")
                    if script_content:
                        # T√¨m URL trong script
                        url_matches = re.findall(r'(https?://[^"\'\s]+\.(?:zip|psd|ai|jpg|png|pdf|eps|rar)[^"\'\s]*)', script_content)
                        for url in url_matches:
                            if "pikbest" in url and not any(keyword in url.lower() for keyword in ['logo', 'icon', 'favicon', 'avatar']):
                                logger.info(f"T√¨m th·∫•y link t·∫£i trong JavaScript: {url}")
                                return url
                except Exception as e:
                    logger.error(f"L·ªói khi ph√¢n t√≠ch script: {e}")
                    continue
        except Exception as e:
            logger.error(f"L·ªói khi t√¨m trong JavaScript: {e}")
        
        # Ph∆∞∆°ng ph√°p 3: Ph√¢n t√≠ch network requests
        logger.info("ƒêang ph√¢n t√≠ch network requests...")
        try:
            # L·∫•y t·∫•t c·∫£ network requests
            all_requests = driver.execute_script("return window.ajaxRequests;")
            if all_requests:
                logger.info(f"T√¨m th·∫•y {len(all_requests)} requests")
                
                # L·ªçc c√°c URL c√≥ th·ªÉ l√† link t·∫£i
                download_candidates = []
                for url in all_requests:
                    if isinstance(url, str) and "pikbest" in url:
                        ext_match = re.search(r'\.(zip|psd|ai|jpg|png|pdf|eps|rar)', url.lower())
                        if ext_match and not any(keyword in url.lower() for keyword in ['logo', 'icon', 'favicon', 'avatar']):
                            download_candidates.append(url)
                
                if download_candidates:
                    logger.info(f"C√°c URL ·ª©ng vi√™n: {download_candidates}")
                    return download_candidates[-1]  # Tr·∫£ v·ªÅ URL m·ªõi nh·∫•t
        except Exception as e:
            logger.error(f"L·ªói khi ph√¢n t√≠ch network requests: {e}")
        
        # Ph∆∞∆°ng ph√°p 4: T√¨m trong performance entries
        logger.info("ƒêang t√¨m trong performance entries...")
        try:
            entries = driver.execute_script("""
                var performance = window.performance || window.mozPerformance || window.msPerformance || window.webkitPerformance || {};
                var entries = performance.getEntries() || [];
                return entries;
            """)
            
            download_candidates = []
            for entry in entries:
                if isinstance(entry, dict) and 'name' in entry:
                    url = entry['name']
                    if isinstance(url, str) and "pikbest" in url:
                        ext_match = re.search(r'\.(zip|psd|ai|jpg|png|pdf|eps|rar)', url.lower())
                        if ext_match and not any(keyword in url.lower() for keyword in ['logo', 'icon', 'favicon', 'avatar']):
                            download_candidates.append(url)
            
            if download_candidates:
                logger.info(f"C√°c URL t·ª´ performance entries: {download_candidates}")
                return download_candidates[-1]  # Tr·∫£ v·ªÅ URL m·ªõi nh·∫•t
        except Exception as e:
            logger.error(f"L·ªói khi t√¨m trong performance entries: {e}")
            
    except Exception as e:
        logger.error(f"L·ªói chung khi t√¨m link t·∫£i: {e}")
    finally:
        driver.quit()

    return None

def is_valid_download_file(url):
    """Ki·ªÉm tra xem URL c√≥ ph·∫£i l√† file t·∫£i h·ª£p l·ªá kh√¥ng (lo·∫°i tr·ª´ logo, icon, v.v.)"""
    if not url:
        return False
        
    # Ki·ªÉm tra ph·∫ßn m·ªü r·ªông file
    ext_match = re.search(r'\.(zip|psd|ai|jpg|png|pdf|eps|rar)(\?|$)', url.lower())
    if not ext_match:
        return False
        
    # Lo·∫°i tr·ª´ c√°c file logo, icon, v.v.
    if any(keyword in url.lower() for keyword in ['logo', 'icon', 'favicon', 'avatar']):
        return False
        
    # Ki·ªÉm tra k√≠ch th∆∞·ªõc file (n·∫øu c√≥ th·ªÉ)
    try:
        response = session.head(url, headers=headers, timeout=5)
        content_length = response.headers.get('Content-Length')
        if content_length and int(content_length) < 10000:  # Nh·ªè h∆°n 10KB c√≥ th·ªÉ l√† icon
            return False
    except:
        pass
        
    return True

def get_file_info(url):
    """L·∫•y th√¥ng tin v·ªÅ file t·ª´ URL"""
    try:
        response = session.head(url, headers=headers, timeout=5)
        
        # L·∫•y k√≠ch th∆∞·ªõc file
        content_length = response.headers.get('Content-Length')
        size_mb = int(content_length) / (1024 * 1024) if content_length else 0
        
        # L·∫•y lo·∫°i file
        content_type = response.headers.get('Content-Type', '')
        
        # L·∫•y t√™n file
        filename = url.split('/')[-1].split('?')[0]
        
        # L·∫•y th·ªùi gian h·∫øt h·∫°n t·ª´ URL
        expiry_time = None
        expiry_match = re.search(r'[?&]e=(\d+)', url)
        if expiry_match:
            try:
                expiry_timestamp = int(expiry_match.group(1))
                expiry_time = time.strftime('%d/%m/%Y %H:%M:%S', time.localtime(expiry_timestamp))
            except:
                expiry_time = "Kh√¥ng x√°c ƒë·ªãnh"
        else:
            expiry_time = "Kh√¥ng x√°c ƒë·ªãnh"
        
        return {
            'filename': filename,
            'size': f"{size_mb:.2f} MB",
            'type': content_type,
            'url': url,
            'expiry': expiry_time
        }
    except Exception as e:
        logger.error(f"L·ªói khi l·∫•y th√¥ng tin file: {e}")
        
        # V·∫´n c·ªë g·∫Øng l·∫•y th·ªùi gian h·∫øt h·∫°n t·ª´ URL
        expiry_time = "Kh√¥ng x√°c ƒë·ªãnh"
        try:
            expiry_match = re.search(r'[?&]e=(\d+)', url)
            if expiry_match:
                expiry_timestamp = int(expiry_match.group(1))
                expiry_time = time.strftime('%d/%m/%Y %H:%M:%S', time.localtime(expiry_timestamp))
        except:
            pass
            
        return {
            'filename': url.split('/')[-1].split('?')[0],
            'size': 'Kh√¥ng x√°c ƒë·ªãnh',
            'type': 'Kh√¥ng x√°c ƒë·ªãnh',
            'url': url,
            'expiry': expiry_time
        }

def extract_file_id(url):
    # X·ª≠ l√Ω nhi·ªÅu ƒë·ªãnh d·∫°ng URL kh√°c nhau
    patterns = [
        r'_([0-9]+)\.html',  # M·∫´u nh∆∞ _10015761.html
        r'/([0-9]+)\.html',  # M·∫´u nh∆∞ /10015761.html
        r'-([0-9]+)\.html',   # M·∫´u nh∆∞ -132883.html
        r'[^0-9]([0-9]{6,})\.html'  # B·∫•t k·ª≥ s·ªë 6+ ch·ªØ s·ªë n√†o tr∆∞·ªõc .html
    ]
    
    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)
    
    # N·∫øu kh√¥ng t√¨m th·∫•y, th·ª≠ ph∆∞∆°ng ph√°p kh√°c
    parts = url.split('/')
    for part in parts:
        if part.isdigit() and len(part) >= 6:  # ID th∆∞·ªùng c√≥ √≠t nh·∫•t 6 ch·ªØ s·ªë
            return part
            
    return None

def process_pikbest_url(user_url):
    file_id = extract_file_id(user_url)
    if not file_id:
        logger.error(f"Kh√¥ng t√¨m th·∫•y ID trong URL: {user_url}")
        print("‚ùå Kh√¥ng t√¨m th·∫•y ID trong URL.")
        return

    print(f"üîç ƒêang x·ª≠ l√Ω ID: {file_id}")
    logger.info(f"ƒêang x·ª≠ l√Ω ID: {file_id} t·ª´ URL: {user_url}")

    real_url = get_real_download_link(file_id)
    if real_url:
        print(f"\nüéØ Link t·∫£i th·∫≠t: {real_url}")
        
        # L·∫•y th√¥ng tin file
        file_info = get_file_info(real_url)
        
        # Hi·ªÉn th·ªã th√¥ng tin file
        print("\nüìÅ Th√¥ng tin file:")
        print(f"  ‚Ä¢ T√™n file: {file_info['filename']}")
        print(f"  ‚Ä¢ K√≠ch th∆∞·ªõc: {file_info['size']}")
        print(f"  ‚Ä¢ Lo·∫°i file: {file_info['type']}")
        print(f"  ‚Ä¢ H·∫øt h·∫°n: {file_info['expiry']}")
        
        # Hi·ªÉn th·ªã h∆∞·ªõng d·∫´n
        print("\nüí° ƒê·ªÉ t·∫£i file, b·∫°n c√≥ th·ªÉ:")
        print("  1. Sao ch√©p link tr√™n v√† d√°n v√†o tr√¨nh duy·ªát")
        print("  2. S·ª≠ d·ª•ng c√¥ng c·ª• t·∫£i xu·ªëng nh∆∞ IDM, wget, curl, v.v.")
        print("  3. S·ª≠ d·ª•ng l·ªánh sau trong terminal:")
        print(f"     curl -o \"{file_info['filename']}\" \"{real_url}\"")
        
        # Hi·ªÉn th·ªã c·∫£nh b√°o n·∫øu link s·∫Øp h·∫øt h·∫°n
        if file_info['expiry'] != "Kh√¥ng x√°c ƒë·ªãnh":
            try:
                expiry_match = re.search(r'[?&]e=(\d+)', real_url)
                if expiry_match:
                    expiry_timestamp = int(expiry_match.group(1))
                    current_time = time.time()
                    hours_left = (expiry_timestamp - current_time) / 3600
                    
                    if hours_left < 24:
                        print(f"\n‚ö†Ô∏è C·∫£nh b√°o: Link s·∫Ω h·∫øt h·∫°n trong {hours_left:.1f} gi·ªù!")
                    elif hours_left < 72:
                        print(f"\n‚ö†Ô∏è C·∫£nh b√°o: Link s·∫Ω h·∫øt h·∫°n trong {hours_left/24:.1f} ng√†y!")
            except:
                pass
        
        return real_url
    else:
        logger.error("Kh√¥ng t√¨m th·∫•y link t·∫£i th·∫≠t")
        print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y link t·∫£i th·∫≠t. Vui l√≤ng ki·ªÉm tra l·∫°i URL ho·∫∑c ƒëƒÉng nh·∫≠p.")
        print("üí° M·∫πo: H√£y ki·ªÉm tra file debug_screenshot.png v√† page_source.html ƒë·ªÉ xem tr·∫°ng th√°i trang.")
        return None

def process_multiple_urls(urls):
    """X·ª≠ l√Ω nhi·ªÅu URL c√πng l√∫c"""
    results = []
    
    for i, url in enumerate(urls, 1):
        print(f"\n[{i}/{len(urls)}] ƒêang x·ª≠ l√Ω: {url}")
        result = process_pikbest_url(url)
        if result:
            results.append(result)
    
    # Hi·ªÉn th·ªã t·ªïng k·∫øt
    if results:
        print("\n‚úÖ T·ªïng k·∫øt:")
        for i, url in enumerate(results, 1):
            print(f"{i}. {url}")
    
    return results

if __name__ == "__main__":
    print("=" * 60)
    print("üîç PIKBEST LINK EXTRACTOR üîç".center(60))
    print("=" * 60)
    print("Tool n√†y gi√∫p l·∫•y link t·∫£i tr·ª±c ti·∫øp t·ª´ Pikbest.com")
    print("B·∫°n c√≥ th·ªÉ nh·∫≠p m·ªôt ho·∫∑c nhi·ªÅu URL, m·ªói URL m·ªôt d√≤ng.")
    print("ƒê·ªÉ k·∫øt th√∫c nh·∫≠p, h√£y nh·∫•n Enter ·ªü d√≤ng tr·ªëng.")
    print("-" * 60)
    
    urls = []
    while True:
        url = input("Nh·∫≠p URL Pikbest (Enter ƒë·ªÉ k·∫øt th√∫c): ").strip()
        if not url:
            break
        urls.append(url)
    
    if urls:
        if len(urls) == 1:
            process_pikbest_url(urls[0])
        else:
            process_multiple_urls(urls)
    else:
        print("Kh√¥ng c√≥ URL n√†o ƒë∆∞·ª£c nh·∫≠p.")
